{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 is available\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'{device} is available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels,self.out_channels, kernel_size=3, stride = stride, padding = 1, bias = False ),\n",
    "            nn.BatchNorm2d(self.out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(self.out_channels,self.out_channels, kernel_size=3, stride = 1, padding = 1, bias = False ),\n",
    "            nn.BatchNorm2d(self.out_channels)\n",
    "        )\n",
    "\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels,self.out_channels, kernel_size=1, stride = stride, bias = False ),\n",
    "            nn.BatchNorm2d(self.out_channels)\n",
    "\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv_block(x)\n",
    "        if self.stride != 1 or self.in_channels != self.out_channels:\n",
    "            x = self.downsample(x)\n",
    "        out = F.relu(x + out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_chnnels = 64\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.layer1 = self._make_layer(64,num_blocks[0], stride = 1)\n",
    "        self.layer2 = self._make_layer(128,num_blocks[1], stride = 2)\n",
    "        self.layer3 = self._make_layer(256,num_blocks[2], stride = 2)\n",
    "        self.layer4 = self._make_layer(512,num_blocks[3], stride = 2)\n",
    "        self.gap = nn.AvgPool2d(4)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride]+[1]*(num_blocks -1)\n",
    "        print(strides)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            block = ResidualBlock(self.in_chnnels, out_channels, stride)\n",
    "            layers.append(block)\n",
    "            self.in_chnnels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.base(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.gap(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeltype(model):\n",
    "    if model == \"resnet18\":\n",
    "        return ResNet([2,2,2,2])\n",
    "    elif model == \"resnet34\":\n",
    "        return ResNet([3,4,6,3])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "              ReLU-3           [-1, 64, 32, 32]               0\n",
      "            Conv2d-4           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
      "              ReLU-6           [-1, 64, 32, 32]               0\n",
      "            Conv2d-7           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-8           [-1, 64, 32, 32]             128\n",
      "     ResidualBlock-9           [-1, 64, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-14           [-1, 64, 32, 32]             128\n",
      "    ResidualBlock-15           [-1, 64, 32, 32]               0\n",
      "           Conv2d-16          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-17          [-1, 128, 16, 16]             256\n",
      "             ReLU-18          [-1, 128, 16, 16]               0\n",
      "           Conv2d-19          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-20          [-1, 128, 16, 16]             256\n",
      "           Conv2d-21          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-22          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-23          [-1, 128, 16, 16]               0\n",
      "           Conv2d-24          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-25          [-1, 128, 16, 16]             256\n",
      "             ReLU-26          [-1, 128, 16, 16]               0\n",
      "           Conv2d-27          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-28          [-1, 128, 16, 16]             256\n",
      "    ResidualBlock-29          [-1, 128, 16, 16]               0\n",
      "           Conv2d-30            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-31            [-1, 256, 8, 8]             512\n",
      "             ReLU-32            [-1, 256, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "           Conv2d-35            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-37            [-1, 256, 8, 8]               0\n",
      "           Conv2d-38            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-39            [-1, 256, 8, 8]             512\n",
      "             ReLU-40            [-1, 256, 8, 8]               0\n",
      "           Conv2d-41            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-42            [-1, 256, 8, 8]             512\n",
      "    ResidualBlock-43            [-1, 256, 8, 8]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-46            [-1, 512, 4, 4]               0\n",
      "           Conv2d-47            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-48            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-49            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-50            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-51            [-1, 512, 4, 4]               0\n",
      "           Conv2d-52            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-53            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-54            [-1, 512, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "    ResidualBlock-57            [-1, 512, 4, 4]               0\n",
      "        AvgPool2d-58            [-1, 512, 1, 1]               0\n",
      "           Linear-59                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 13.63\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 56.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet, (3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (base): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualBlock(\n",
      "      (conv_block): Sequential(\n",
      "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (gap): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resnet = modeltype(\"resnet18\").to(device)\n",
    "print(resnet)\n",
    "path = \"./model/cifar_resnet.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.361\n",
      "[2] loss: 0.846\n",
      "[3] loss: 0.625\n",
      "[4] loss: 0.483\n",
      "[5] loss: 0.369\n",
      "[6] loss: 0.272\n",
      "[7] loss: 0.191\n",
      "[8] loss: 0.135\n",
      "[9] loss: 0.104\n",
      "[10] loss: 0.081\n",
      "[11] loss: 0.072\n",
      "[12] loss: 0.061\n",
      "[13] loss: 0.051\n",
      "[14] loss: 0.055\n",
      "[15] loss: 0.044\n",
      "[16] loss: 0.039\n",
      "[17] loss: 0.037\n",
      "[18] loss: 0.032\n",
      "[19] loss: 0.035\n",
      "[20] loss: 0.030\n",
      "[21] loss: 0.027\n",
      "[22] loss: 0.028\n",
      "[23] loss: 0.026\n",
      "[24] loss: 0.025\n",
      "[25] loss: 0.024\n",
      "[26] loss: 0.021\n",
      "[27] loss: 0.022\n",
      "[28] loss: 0.021\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-3a1af3330032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'betas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_ = []\n",
    "n = len(trainloader)\n",
    "\n",
    "for epoch in range(50):\n",
    "    running_loss = 0.0\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = resnet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    loss_.append(running_loss / n)\n",
    "    print('[%d] loss: %.3f'%(epoch+1, running_loss / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(resnet.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = modeltype(\"resnet18\").to(device)\n",
    "resnet.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 84.74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    resnet.eval()\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = resnet(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(\"Test accuracy: %.2f %%\"%(100 * correct / total) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f7b3696bbf49b2a50ef1adf7077f2aae425138456588ce2492db2fb5bbf26d67"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
